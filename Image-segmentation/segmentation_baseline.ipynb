{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1299bced-ba1d-4b93-bca1-df10796ec35f",
   "metadata": {},
   "source": [
    "## Setting up\n",
    "### Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c1fd5b-eef6-4b9a-92fe-80001960e916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 설치되지 않은 라이브러리의 경우, 주석 해제 후 코드를 실행하여 설치\n",
    "# !pip install segmentation-models-pytorch\n",
    "# !pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609b08b3-850e-4e74-a781-982b99e9439f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import segmentation_models_pytorch as smp\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as albu\n",
    "import json\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd8d295-8df4-4a57-b9b0-3d7042b12884",
   "metadata": {
    "tags": []
   },
   "source": [
    "### etc..\n",
    "- working directory  \n",
    "  |--code.ipynb  \n",
    "  |--data/  \n",
    "  |--|--train/  \n",
    "  |--|--|--images/  \n",
    "  |--|--|--|--...  \n",
    "  |--|--|--labels.json  \n",
    "  |--|--test/  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537fe83f-e43c-4f68-9888-cb8ef3e180de",
   "metadata": {},
   "source": [
    "#### fill the blanks!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9375d483-2476-4dc1-92d1-dd4193a42e05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# seed\n",
    "RANDOM_SEED = ##### value #####\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# Set device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ##### value #####\n",
    "# torch.cuda.set_device(1)\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# directory\n",
    "DATA_DIR = ##### directory #####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2137266d-69c3-405e-affa-d1653dfa8c61",
   "metadata": {},
   "source": [
    "## Dataload\n",
    "\n",
    "you can add Augmentation, preprocessing part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf2a9c9-faf5-4b27-9f22-a7ebcd7abf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "EVAL_BATCH_SIZE = 32\n",
    "VAL_RATIO = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7017991-7254-4637-9c05-3b7ec865e1a3",
   "metadata": {},
   "source": [
    "#### fill the blanks!\n",
    "  (`##### code #####` part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65144d9c-9f7a-4121-aa6a-b8cf08be44e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygon_to_mask(json_file, filename):\n",
    "   \n",
    "        # n : n.jpg\n",
    "        n = int(filename.split('.')[0])\n",
    "        file_dict = json_file['annotations'][n]\n",
    "           \n",
    "        class_name = []\n",
    "        polygon_dict = []\n",
    "        \n",
    "        polygon_dict = []\n",
    "        class_name = []\n",
    "        mask = []\n",
    "        \n",
    "        if len(file_dict['objects']) == 0:\n",
    "            mask_ = []\n",
    "            img = Image.new('L', (720,480), 'black')\n",
    "            img = img.resize((512,512))\n",
    "            mask_.append(np.array(img))\n",
    "            class_name.append(0)\n",
    "            mask_[0] = np.where(mask_[0]!=0, 0, mask_[0])\n",
    "            \n",
    "        else:\n",
    "            for i in range(len(file_dict['objects'])):\n",
    "                mask_ = []\n",
    "                clss = file_dict['objects'][i]['class']\n",
    "                poly = np.array(file_dict['objects'][i]['polygon'], np.float32)\n",
    "                                \n",
    "                img = Image.new('L', (720,480), 'black')\n",
    "                \n",
    "                ImageDraw.Draw(img).polygon(poly, outline='white', fill='white')\n",
    "                img = img.resize((512,512))\n",
    "                mask_.append(np.array(img))\n",
    "                idx = len(mask_)-1\n",
    "                mask_[idx] = np.where(mask_[idx]!=0, clss, mask_[idx])             \n",
    "                class_name.append(clss)\n",
    "                \n",
    "            if np.any(class_name[:]) > 4:\n",
    "                print(\"filename : \", filename, \" class : \", clss_name)                 \n",
    "        \n",
    "        # combine masks\n",
    "        mask = ##### code #####\n",
    "\n",
    "        return mask, class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea4eb1c-e3bd-4845-9421-429fc00a4dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "            self, \n",
    "            mode = 'train',\n",
    "            data_dir = DATA_DIR,\n",
    "            val_ratio = VAL_RATIO,\n",
    "            augmentation=None, \n",
    "            preprocessing=None\n",
    "            \n",
    "    ):\n",
    "        # 데이터 위치 설정\n",
    "        path = ##### 경로 #####\n",
    "        self.path = path\n",
    "        self.json_file = json.load(open(os.path.join(path,'labels.json')))\n",
    "        df = self.get_filelist()\n",
    "        \n",
    "        # file_names : 파일명 리스트, 이미지-레이블-마스크 모두 파일명으로 매칭됨\n",
    "            \n",
    "        train_df, val_df = train_test_split(df,test_size=val_ratio, shuffle=True, random_state=42)       \n",
    "        \n",
    "        # TRAIN_RATIO 로 학습/추론 데이터 분할\n",
    "        if mode == 'train':\n",
    "            self.file_names = train_df\n",
    "            \n",
    "        elif mode =='valid':\n",
    "            self.file_names = val_df\n",
    "\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "   \n",
    "    def get_filelist(self):\n",
    "        \n",
    "        filenames = os.listdir(os.path.join(self.path, 'train'))\n",
    "        filenames = [file for file in filenames if \".jpg\" in file]\n",
    "        \n",
    "        return filenames\n",
    "        \n",
    "\n",
    "    # i번째 이미지와 마스크를 리턴\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        img_fps = os.path.join(self.path, 'train', self.file_names[i])\n",
    "        image = ##### 코드 #####\n",
    "        image = cv2.resize(image, (512,512))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        mask = []\n",
    "        \n",
    "        mask, c = polygon_to_mask(self.json_file, self.file_names[i])\n",
    "\n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return image, mask.squeeze(0)\n",
    "    \n",
    "    # 이미지 파일 수를 리턴\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34285fe-87e6-47a4-9062-5197806ba650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "def img_to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 1, 0).astype('float32')\n",
    "\n",
    "def mask_to_tensor(x, **kwargs):\n",
    "    return x.transpose(0 ,2, 1).astype('int32')\n",
    "\n",
    "# smp의 전처리 함수를 데이터 로드에 사용하기 위한 변환\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    _transform = [\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "        albu.Lambda(image=img_to_tensor, mask=mask_to_tensor),\n",
    "    ]\n",
    "    return albu.Compose(_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeefc761-d7fe-43df-98d6-2a5b4fdcd0e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Building the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72ea880-d690-4e42-8acb-acb3701731e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "EPOCHS = ##### value #####\n",
    "LEARNING_RATE = ##### value #####\n",
    "WEIGHT_DECAY = ##### value #####\n",
    "NUM_WORKERS = ##### value #####\n",
    "PIN_MEMORY = True\n",
    "\n",
    "ENCODER = 'efficientnet-b0' # 예시\n",
    "ENCODER_WEIGHTS = 'imagenet' # 예시\n",
    "CLASSES = ['background', 'black', 'gray', 'white', 'fire']\n",
    "ACTIVATION = None # 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27a4cd1-3edd-48bc-9947-1896fddae493",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=len(CLASSES), \n",
    "    activation=ACTIVATION,\n",
    ")\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20339d2a-81dd-4bd6-89bb-9c7a95931a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset & dataloader using preprocessing fn\n",
    "\n",
    "train_dataset = CustomDataset(\n",
    "    mode = 'train',\n",
    "    data_dir = DATA_DIR,\n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    ")\n",
    "\n",
    "val_dataset = CustomDataset(\n",
    "    mode = 'valid',\n",
    "    data_dir = DATA_DIR,\n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, shuffle=True)\n",
    "valid_loader = DataLoader(val_dataset, batch_size=EVAL_BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6392e4-861d-4502-bba1-d057c0f5f65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fba482-9b47-4512-8b6a-e16447a8ca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "def mIoU(pred_mask, mask, smooth=1e-10, n_classes=5):\n",
    "    with torch.no_grad():\n",
    "        pred_mask = F.softmax(pred_mask, dim=1)\n",
    "        pred_mask = torch.argmax(pred_mask, dim=1)\n",
    "        pred_mask = pred_mask.contiguous().view(-1)\n",
    "        mask = mask.contiguous().view(-1)\n",
    "\n",
    "        iou_per_class = []\n",
    "        for clas in range(0, n_classes): #loop per pixel class\n",
    "            true_class = pred_mask == clas\n",
    "            true_label = mask == clas\n",
    "\n",
    "            if true_label.long().sum().item() == 0: #no exist label in this loop\n",
    "                iou_per_class.append(np.nan)\n",
    "            else:\n",
    "                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n",
    "                union = torch.logical_or(true_class, true_label).sum().float().item()\n",
    "\n",
    "                iou = (intersect + smooth) / (union +smooth)\n",
    "                iou_per_class.append(iou)\n",
    "        return np.nanmean(iou_per_class)\n",
    "\n",
    "def fit(epochs, model, train_loader, val_loader, criterion, optimizer, scheduler, patch=False):\n",
    "    torch.cuda.empty_cache()\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    val_iou = []; \n",
    "    train_iou = [];\n",
    "    lrs = []\n",
    "    min_loss = np.inf\n",
    "    decrease = 1 ; not_improve=0\n",
    "\n",
    "    model.to(DEVICE)\n",
    "    fit_time = time.time()\n",
    "    for e in range(epochs):\n",
    "        since = time.time()\n",
    "        running_loss = 0\n",
    "        iou_score = 0\n",
    "        #training loop\n",
    "        model.train()\n",
    "        for i, data in enumerate(tqdm(train_loader)):\n",
    "            #training phase\n",
    "            image_tiles, mask_tiles = data\n",
    "            mask_tiles = mask_tiles.long().squeeze(1)\n",
    "            \n",
    "            if patch:\n",
    "                print(image_tiles.size())\n",
    "                bs, c, h, w = image_tiles.size()\n",
    "\n",
    "                image_tiles = image_tiles.view(-1,c, h, w)\n",
    "                mask_tiles = mask_tiles.view(-1, h, w)\n",
    "            \n",
    "            image = image_tiles.to(DEVICE); mask = mask_tiles.to(DEVICE);\n",
    "            #forward\n",
    "            output = ##### 코드 #####\n",
    "            loss = ##### 코드 #####\n",
    "            #evaluation metrics\n",
    "            iou_score += mIoU(output, mask)\n",
    "            #backward\n",
    "            loss.backward()\n",
    "            optimizer.step() #update weight          \n",
    "            optimizer.zero_grad() #reset gradient\n",
    "            \n",
    "            #step the learning rate\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            scheduler.step() \n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        else:\n",
    "            model.eval()\n",
    "            test_loss = 0\n",
    "            val_iou_score = 0\n",
    "            #validation loop\n",
    "            with torch.no_grad():\n",
    "                for i, data in enumerate(tqdm(val_loader)):\n",
    "                    #reshape to 9 patches from single image, delete batch size\n",
    "                    image_tiles, mask_tiles = data\n",
    "                    mask_tiles = mask_tiles.long()\n",
    "\n",
    "                    if patch:\n",
    "                        print(image_tiles.size())\n",
    "                        bs, c, h, w = image_tiles.size()\n",
    "\n",
    "                        image_tiles = image_tiles.view(-1,c, h, w)\n",
    "                        mask_tiles = mask_tiles.view(-1, h, w)\n",
    "                    \n",
    "                    image = image_tiles.to(DEVICE); mask = mask_tiles.to(DEVICE);\n",
    "                    output = ##### 코드 #####\n",
    "                    #evaluation metrics\n",
    "                    val_iou_score +=  mIoU(output, mask)\n",
    "                    #loss\n",
    "                    loss = ##### 코드 #####                                 \n",
    "                    test_loss += loss.item()\n",
    "            \n",
    "            #calculatio mean for each batch\n",
    "            train_losses.append(running_loss/len(train_loader))\n",
    "            test_losses.append(test_loss/len(val_loader))\n",
    "\n",
    "\n",
    "            if min_loss > (test_loss/len(val_loader)):\n",
    "                print('Loss Decreasing.. {:.3f} >> {:.3f} '.format(min_loss, (test_loss/len(val_loader))))\n",
    "                min_loss = (test_loss/len(val_loader))\n",
    "                decrease += 1\n",
    "                if decrease % 5 == 0:\n",
    "                    print('saving model...')\n",
    "                    torch.save(model, 'model_best.pt'.format(val_iou_score/len(val_loader)))\n",
    "                    \n",
    "\n",
    "            if (test_loss/len(val_loader)) > min_loss:\n",
    "                not_improve += 1\n",
    "                min_loss = (test_loss/len(val_loader))\n",
    "                print(f'Loss Not Decrease for {not_improve} time')\n",
    "                if not_improve == 7:\n",
    "                    print('Loss not decrease for 7 times, Stop Training')\n",
    "                    break\n",
    "            \n",
    "            #iou\n",
    "            val_iou.append(val_iou_score/len(val_loader))\n",
    "            train_iou.append(iou_score/len(train_loader))\n",
    "            print(\"Epoch:{}/{}..\".format(e+1, epochs),\n",
    "                  \"Train Loss: {:.3f}..\".format(running_loss/len(train_loader)),\n",
    "                  \"Val Loss: {:.3f}..\".format(test_loss/len(val_loader)),\n",
    "                  \"Train mIoU:{:.3f}..\".format(iou_score/len(train_loader)),\n",
    "                  \"Val mIoU: {:.3f}..\".format(val_iou_score/len(val_loader)),\n",
    "                  \"Time: {:.2f}m\".format((time.time()-since)/60))\n",
    "        \n",
    "    history = {'train_loss' : train_losses, 'val_loss': test_losses,\n",
    "               'train_miou' :train_iou, 'val_miou':val_iou,\n",
    "               'lrs': lrs}\n",
    "    print('Total time: {:.2f} m' .format((time.time()- fit_time)/60))\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff86558-25f3-4883-980d-46170af5de7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() #예시\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY) #예시\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, LEARNING_RATE, epochs=EPOCHS,\n",
    "                                            steps_per_epoch=len(train_loader)) #예시\n",
    "\n",
    "# train start\n",
    "history = fit(EPOCHS, model, train_loader, valid_loader, criterion, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43251bd-6ca1-4f5e-a70f-08c24dc64e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model_final.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88d9b05-e7a5-4091-b3ba-921999bca0f2",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770569c0-a639-4151-bdc0-7ae6a37a942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submission\n",
    "sub_json = json.load(open('sample_submission.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c90dd96-0be5-4ea9-9e02-b37538567e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_json['annotations'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17abf82c-9979-4634-b3c3-298c1518be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA_DIR = ##### 경로 #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d70f309-39cb-4365-aaa1-46370f2bdb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(\n",
    "            self, \n",
    "            mode = 'test',\n",
    "            data_dir = TEST_DATA_DIR,\n",
    "            classes=None,\n",
    "            augmentation=None, \n",
    "            preprocessing=None\n",
    "            \n",
    "    ):\n",
    "        # 데이터 위치 설정\n",
    "        path = ##### 경로 #####\n",
    "        \n",
    "        # file_names : 파일명 리스트, 이미지-레이블-마스크 모두 파일명으로 매칭됨\n",
    "        self.file_names = glob(os.path.join(path, '*.jpg'))\n",
    "        \n",
    "        self.images_fps = [os.path.join(path, 'images', i) for i in self.file_names]\n",
    "\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "   \n",
    "\n",
    "    # i번째 이미지와 마스크를 리턴\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image = cv2.imread(self.images_fps[i])\n",
    "        image = cv2.resize(image, (512,512))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image)\n",
    "            image = sample['image']\n",
    "            \n",
    "        return image\n",
    "    \n",
    "    # 이미지 파일 수를 리턴\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd2c62d-730e-40ab-9951-f9964d2e140b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "def img_to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 1, 0).astype('float32')\n",
    "\n",
    "def mask_to_tensor(x, **kwargs):\n",
    "    return x.transpose(0 ,2, 1).astype('float32')\n",
    "\n",
    "# smp의 전처리 함수를 데이터 로드에 사용하기 위한 변환\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    _transform = [\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "        albu.Lambda(image=img_to_tensor),\n",
    "    ]\n",
    "    return albu.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7589964-9da3-4c92-a9ad-c52ff13464ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(\n",
    "    mode = 'test',\n",
    "    data_dir = TEST_DATA_DIR,\n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=EVAL_BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8055ba-9432-4cb0-96fc-de6085dc3a9b",
   "metadata": {},
   "source": [
    "#### 코드 채워넣기\n",
    "- 경로 설정을 완성하세요.  \n",
    "  (`##### 경로 #####` 부분)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45711020-4ce9-44ef-97c5-6e2d84f19369",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=len(CLASSES), \n",
    "    activation=ACTIVATION,\n",
    ")\n",
    "\n",
    "MODEL_DIR = ##### 경로 #####\n",
    "model = torch.load(MODEL_DIR)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424167b0-8590-4126-bc3b-b8d057853f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 결과 저장\n",
    "preds = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for i, batch_data in enumerate(tqdm(test_loader)):\n",
    "        x = batch_data.to(DEVICE)\n",
    "        output = model.predict(x)\n",
    "        mask = torch.argmax(output, dim=1)\n",
    "        preds.extend(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2d0606-4053-46fb-8744-ddbe17d8403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result = {'annotations':[]}\n",
    "wratio = 720/512\n",
    "hratio = 480/512\n",
    "\n",
    "for i, file in enumerate(test_dataset.file_names):\n",
    "    \n",
    "    file_name = ##### 코드 #####\n",
    "    objects = []\n",
    "    pred = np.array(preds[i].cpu()) \n",
    "    \n",
    "    # background 제외\n",
    "    for c in range(1,len(CLASSES)):\n",
    "        clss = np.full((512,512),c) #필터\n",
    "        layer = np.equal(pred, clss).astype('int')\n",
    "        if layer.sum()!=0:\n",
    "           \n",
    "            # findContours에 들어갈 이미지 형태로 변환\n",
    "            layer = np.array(layer*255).astype('uint8')\n",
    "            contours, _ = cv2.findContours(layer, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            # contours[2] = contour의 좌표 리스트\n",
    "            polygon=[]\n",
    "\n",
    "            for a in contours:\n",
    "                for point in a:\n",
    "                    x = point[0][0]*wratio\n",
    "                    y = ##### 코드 ######\n",
    "                    x = np.round(x, 1)\n",
    "                    y = np.round(y, 1)\n",
    "                    polygon.append([x,y])\n",
    "\n",
    "            # 채점은 점이 3개 이상이어야만 하기 때문에, 폐곡선이 아닌 경우 점을 추가\n",
    "            if len(polygon) == 1:\n",
    "                polygon.append(##### 코드 #####)\n",
    "                polygon.append(polygon[0])\n",
    "            elif len(polygon) == 2:\n",
    "                polygon.append(polygon[0])\n",
    "\n",
    "            objects.append({'class':c, 'polygon': polygon})\n",
    "            \n",
    "    \n",
    "    pred_result['annotations'].append({'file_name':file_name, 'objects':objects})\n",
    "    \n",
    "print('Predict Completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec66c7a-5100-4547-bfae-609c3ec44d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(pred_result,open(##### 경로 #####, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9a0286-95ed-4966-8b0a-a28f5c18b115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2645bd5-bfb5-43a0-99f7-70ddc49bcbf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
